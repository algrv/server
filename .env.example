# .env.example
# Copy this to .env and fill in your actual values

# ============================================================================
# DATABASE
# ============================================================================

# Supabase Connection String
# Format: postgresql://postgres:[YOUR-PASSWORD]@[YOUR-PROJECT-REF].supabase.co:5432/postgres
# Get from: Supabase Dashboard → Project Settings → Database → Connection String (URI)
SUPABASE_CONNECTION_STRING=postgresql://postgres:your-password@your-project.supabase.co:5432/postgres

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# --- Query Transformer (expands user queries into technical keywords) ---
# Provider: "anthropic" or "openai"
TRANSFORMER_PROVIDER=anthropic

# Anthropic API Key (for Claude models)
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Transformer Model
# Options: claude-3-haiku-20240307 (fast, cheap), claude-3-sonnet-20240229 (balanced), claude-opus-4-20250514 (powerful)
TRANSFORMER_MODEL=claude-3-haiku-20240307

# --- Embedder (generates vector embeddings from text) ---
# Provider: "openai" (more providers coming soon: cohere, voyage, etc.)
EMBEDDER_PROVIDER=openai

# OpenAI API Key (for embeddings)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key-here

# Embedder Model
# Options: text-embedding-3-small (1536 dims, fast), text-embedding-3-large (3072 dims, more accurate)
EMBEDDER_MODEL=text-embedding-3-small

# ============================================================================
# OPTIONAL CONFIGURATION (defaults shown)
# ============================================================================

# Query transformation settings
TRANSFORMER_MAX_TOKENS=200        # Max tokens for query expansion
TRANSFORMER_TEMPERATURE=0.3       # Lower = more focused, higher = more creative

# Retrieval settings
RETRIEVAL_TOP_K=5                 # Number of doc chunks to retrieve

# Chunking settings (for ingestion)
CHUNK_TARGET_TOKENS=500           # Target tokens per chunk
CHUNK_OVERLAP_TOKENS=50           # Overlap between chunks
